> Reference: [Running PyTorch on RTX 5090 and 5080 GPUs](https://docs.salad.com/tutorials/pytorch-rtx5090#dockerfile)


NVIDIAì˜ ìƒˆë¡œìš´ **RTX 5090 ë° RTX 5080 GPU**ëŠ” **CUDA 12.8**ì„ í•„ìš”ë¡œ í•˜ì§€ë§Œ, í˜„ì¬ PyTorch ê³µì‹ ë¦´ë¦¬ìŠ¤ëŠ” ì´ë¥¼ ì•„ì§ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  
ì´ ê°€ì´ë“œê°€ ìµœì‹ ì´ ì•„ë‹ ìˆ˜ ìˆìœ¼ë‹ˆ [ì—¬ê¸°](https://pytorch.org)ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.

ì´ íŠœí† ë¦¬ì–¼ì€ **PyTorch Nightly ë¹Œë“œ**ë¥¼ ì‚¬ìš©í•˜ì—¬ RTX 50-ì‹œë¦¬ì¦ˆ GPUì—ì„œ PyTorchë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ìš°íšŒ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

ë§Œì•½ RTX 50 ì‹œë¦¬ì¦ˆ GPUì™€ ê¸°ì¡´ì˜ 40 ë˜ëŠ” 30 ì‹œë¦¬ì¦ˆ GPU ëª¨ë‘ì—ì„œ ì›Œí¬ë¡œë“œë¥¼ ì‹¤í–‰í•˜ë ¤ í•œë‹¤ë©´, **ë³„ë„ì˜ Docker ì´ë¯¸ì§€**ë¥¼ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.  
ì‘ì„± ì‹œì  ê¸°ì¤€ìœ¼ë¡œ, **ê¸°ì¡´ GPUëŠ” CUDA 12.8ì„ ì§€ì›í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—**, RTX 50 ì‹œë¦¬ì¦ˆìš©ìœ¼ë¡œ ë¹Œë“œí•œ ì´ë¯¸ì§€ëŠ” êµ¬í˜• GPUì—ì„œëŠ” ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.


# ğŸ³ Dockerfile

ë‹¤ìŒ Dockerfileì€ RTX 50-ì‹œë¦¬ì¦ˆ GPUì—ì„œ PyTorchë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ **í•„ìˆ˜ ì˜ì¡´ì„±ë“¤ì„ í¬í•¨í•˜ëŠ” ì»¨í…Œì´ë„ˆ í™˜ê²½**ì„ ì„¤ì •í•©ë‹ˆë‹¤.

- ê¸°ë³¸ ë² ì´ìŠ¤ ì´ë¯¸ì§€ëŠ” `nvidia/cuda`ì˜ ê³µì‹ ì´ë¯¸ì§€ì´ë©°, `CUDA 12.8.1`ì˜ **runtime** ë²„ì „ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
- `devel` ë²„ì „ë„ ì¡´ì¬í•˜ë©°, [ì—¬ê¸°ì„œ íƒœê·¸ ëª©ë¡](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/cuda/tags)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì´í›„ Python í™˜ê²½ì„ êµ¬ì„±í•˜ê³ , CUDA 12.8ì— ë§ì¶˜ **PyTorch Nightly ë¹Œë“œ**ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```dockerfile
FROM nvcr.io/nvidia/cuda:12.8.1-cudnn-runtime-ubuntu24.04
ENV DEBIAN_FRONTEND=noninteractive

RUN apt update -y && apt install -y \
    wget \
    curl \
    git \
    python3 \
    python3-pip \
    python3-venv \
    unzip \
    && rm -rf /var/lib/apt/lists/*

RUN python3 -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
RUN . /opt/venv/bin/activate

RUN pip install --upgrade pip
RUN pip install --pre torch torchvision torchaudio \
    --index-url https://download.pytorch.org/whl/nightly/cu128
```

---

# ğŸ› ï¸ Build (ì´ë¯¸ì§€ ë¹Œë“œí•˜ê¸°)


```bash
docker build -t test/pytorch:nightly-cuda12.8-cudnn9-runtime .
```


# ğŸš€ ì‚¬ìš© ë°©ë²•

ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•œ í›„ì—ëŠ” ê¸°ì¡´ PyTorch ë² ì´ìŠ¤ ì´ë¯¸ì§€ì²˜ëŸ¼ `Dockerfile`ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:


```bash
docker build -t test/pytorch:nightly-cuda12.8-cudnn9-runtime --push .
```


```dockerfile
# ì´ì „ ë²„ì „ ì˜ˆì‹œ: pytorch/pytorch:2.6.0-cuda12.6-cudnn8-runtime
FROM test/pytorch:nightly-cuda12.8-cudnn9-runtime

# ì›í•˜ëŠ” ì‘ì—…ì„ ì—¬ê¸°ì— ì‘ì„±
```

ì´ì œ ìµœì‹  **PyTorch Nightly ë¹Œë“œ**ë¥¼ í†µí•´ **RTX 50-ì‹œë¦¬ì¦ˆ GPUì—ì„œ PyTorchë¥¼ ì‹¤í–‰**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!  
ì´ ë°©ë²•ì„ í†µí•´ ìµœì‹  í•˜ë“œì›¨ì–´ì—ì„œ CUDA 12.8ì˜ ì„±ëŠ¥ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

Docker ì´ë¯¸ì§€ ë¹Œë“œ í›„ **ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•˜ê³  PyTorchê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì ˆì°¨**ë¥¼ ì¶”ê°€í•œ ì„¹ì…˜ì…ë‹ˆë‹¤. 
`docker run`, `nvidia-smi`, ê·¸ë¦¬ê³  í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ê¹Œì§€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.


# ğŸ§ª ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸ ë°©ë²•

ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•œ í›„, ë‹¤ìŒê³¼ ê°™ì€ ì ˆì°¨ë¡œ ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•˜ê³  PyTorch í™˜ê²½ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ§± 1. ì»¨í…Œì´ë„ˆ ì‹¤í–‰

```bash
docker run --rm -it --gpus all test/pytorch:nightly-cuda12.8-cudnn9-runtime /bin/bash
```

- `--gpus all`: Dockerì—ì„œ NVIDIA GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì • (NVIDIA Container Toolkit í•„ìš”)
- `--rm`: ì¢…ë£Œ ì‹œ ìë™ ì‚­ì œ
- `-it`: ëŒ€í™”í˜• í„°ë¯¸ë„

> ğŸ’¡ `nvidia-container-toolkit`ì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ GPUê°€ ì»¨í…Œì´ë„ˆì—ì„œ ì¸ì‹ë©ë‹ˆë‹¤. ì„¤ì¹˜ ë°©ë²•: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html


### Error

ì•„ë˜ì™€ ê°™ì€ ì—ëŸ¬ê°€ ë‚˜ì˜¨ë‹¤ë©´,
```
docker: Error response from daemon: could not select device driver "" with capabilities: [[gpu]]

```

- cuda ì„¤ì¹˜ ì§„í–‰
    - https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=24.04&target_type=runfile_local

```
wget https://developer.download.nvidia.com/compute/cuda/12.8.1/local_installers/cuda_12.8.1_570.124.06_linux.run
sudo sh cuda_12.8.1_570.124.06_linux.run
```

```
sudo apt install nvidia-cuda-toolkit
```

---

## ğŸ§  2. PyTorch í…ŒìŠ¤íŠ¸

ì»¨í…Œì´ë„ˆ ì•ˆì—ì„œ ì•„ë˜ Python ì½”ë“œë¥¼ ì…ë ¥í•˜ê±°ë‚˜, `test_torch.py` íŒŒì¼ë¡œ ì €ì¥í•´ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
python
```

```python
import torch
print("PyTorch version:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("CUDA device:", torch.cuda.get_device_name(0))
    print("Tensor test:", torch.randn(3, 3).cuda() @ torch.randn(3, 3).cuda())
```

ë˜ëŠ” `test_torch.py`ë¥¼ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ë¡œ ë³µì‚¬í•´ì„œ ì‹¤í–‰:

```bash
docker cp test_torch.py <container_id>:/test_torch.py
docker exec -it <container_id> python /test_torch.py
```

---

## ğŸ§Š 3. `nvidia-smi` í™•ì¸

GPUê°€ ì •ìƒì ìœ¼ë¡œ ì¸ì‹ë˜ëŠ”ì§€ë„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
nvidia-smi
```

ì •ìƒì ìœ¼ë¡œ ì‘ë™í•œë‹¤ë©´, RTX 5090/5080ì´ ì¶œë ¥ë˜ê³  PyTorchì—ì„œ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

---

## âœ… ì˜ˆì‹œ ì¶œë ¥ (ì •ìƒ ì‘ë™ ì‹œ)

```
PyTorch version: 2.8.0.dev20250324+cu128
CUDA available: True
CUDA device: NVIDIA GeForce RTX 5090
Tensor test: tensor([...], device='cuda:0')
```

---

## ğŸ“Œ ì°¸ê³ 

- ë§Œì•½ `torch.cuda.is_available()`ì´ `False`ë¥¼ ë°˜í™˜í•˜ê±°ë‚˜ `nvidia-smi`ì—ì„œ GPUê°€ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤ë©´:
  - í˜¸ìŠ¤íŠ¸ì— NVIDIA ë“œë¼ì´ë²„ ë˜ëŠ” Container Toolkitì´ ì œëŒ€ë¡œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
  - Docker Desktop ì‚¬ìš© ì‹œ GPU ì•¡ì„¸ìŠ¤ ê¶Œí•œì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ë„ í™•ì¸í•˜ì„¸ìš”.

---

ì´ì œ ì—¬ëŸ¬ë¶„ì€ **ìµœì‹  PyTorch Nightly (CUDA 12.8)** í™˜ê²½ì„ RTX 50 ì‹œë¦¬ì¦ˆ GPUì—ì„œ ì™„ì „íˆ ì‹¤í–‰í•˜ê³  ê²€ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ‰

> ğŸ”— **Reference:** [Running PyTorch on RTX 5090 and 5080 GPUs](https://docs.salad.com/tutorials/pytorch-rtx5090#dockerfile)  
> ğŸ”— **PyTorch Nightly CUDA 12.8 builds:** [pytorch.org](https://pytorch.org)